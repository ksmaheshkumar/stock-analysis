{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############DATA CLEANING############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "NmUf7NYojuCv",
    "outputId": "42a42056-41a0-4d1f-846b-62d47e8152b8"
   },
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_db(dbname):\n",
    "    \"\"\"\n",
    "    Setup sqlite connection and returns the dataframe\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(dbname)\n",
    "    # load table to dataframe\n",
    "    tdf = pd.read_sql(\"SELECT * FROM eod\", \n",
    "                 conn, parse_dates=\"date\")\n",
    "    conn.close()\n",
    "    print(tdf.head())\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_columns(tdf):\n",
    "    \"\"\"\n",
    "    Optimize the memory allocation of the columns\n",
    "    \"\"\"\n",
    "    tdf['open'] = tdf['open'].astype(float)\n",
    "    tdf['high'] = tdf['high'].astype(float)\n",
    "    tdf['low'] = tdf['low'].astype(float)\n",
    "    tdf['close'] = tdf['close'].astype(float)\n",
    "    tdf['adjclose'] = tdf['adjclose'].astype(float)\n",
    "    tdf['volume'] = tdf['volume'].astype(int)\n",
    "    print(tdf.memory_usage())\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_columns(tdf, labels):\n",
    "    \"\"\"\n",
    "    Removes unwanted columns by taking the labels\n",
    "    \"\"\"\n",
    "    tdf = tdf.drop(labels=labels, axis=1)\n",
    "    print(tdf.head())\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "LXDrd3P-wgyE",
    "outputId": "80118a00-30a9-4513-ef25-d153a16ffa00"
   },
   "outputs": [],
   "source": [
    "def index_operations(tdf):\n",
    "    \"\"\"\n",
    "    Performs preliminery index operations\n",
    "    \"\"\"\n",
    "    # Add new company column - same as ticker\n",
    "    tdf['company'] = tdf[\"symbol\"]\n",
    "    # Make symbol as index\n",
    "    tdf.set_index(keys= \"symbol\", inplace = True, append=False)\n",
    "    # Make date as index\n",
    "    tdf.set_index(keys= \"date\", inplace = True, append=True)\n",
    "    # Sort the entire dataset\n",
    "    tdf.sort_index(inplace=True)\n",
    "    print(tdf.head())\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_newdf(tdf, fromdate):\n",
    "    \"\"\"\n",
    "    Creates new df and resamples date to weekly(friday)\n",
    "    \"\"\"\n",
    "    # Copy the index structure\n",
    "    ndf = pd.DataFrame(index=tdf.index)\n",
    "    # Resample to weekly\n",
    "    ndf = ndf.groupby([pd.Grouper(level='symbol'), pd.Grouper(level='date', freq='W-FRI')]).first()\n",
    "    # Get values only from date\n",
    "    ndf = ndf[ndf.index.get_level_values(\"date\") > fromdate]\n",
    "    print(ndf.head())\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_columns(tdf, ttdf):\n",
    "    \"\"\"\n",
    "    Resamples OHLCV to weekly data\n",
    "    \"\"\"\n",
    "    # Add resampled columns\n",
    "    ttdf['company'] = tdf['company'].groupby([pd.Grouper(level='symbol'), pd.Grouper(level='date', freq='W-FRI')]).first()\n",
    "    ttdf['open'] = tdf['open'].groupby([pd.Grouper(level='symbol'), pd.Grouper(level='date', freq='W-FRI')]).first()\n",
    "    ttdf['high'] = tdf['high'].groupby([pd.Grouper(level='symbol'), pd.Grouper(level='date', freq='W-FRI')]).max()\n",
    "    ttdf['low'] = tdf['low'].groupby([pd.Grouper(level='symbol'), pd.Grouper(level='date', freq='W-FRI')]).min()\n",
    "    ttdf['close'] = df['close'].groupby([pd.Grouper(level='symbol'), pd.Grouper(level='date', freq='W-FRI')]).last()\n",
    "    ttdf['adjclose'] = tdf['adjclose'].groupby([pd.Grouper(level='symbol'), pd.Grouper(level='date', freq='W-FRI')]).last()\n",
    "    ttdf['volume'] = tdf['volume'].groupby([pd.Grouper(level='symbol'), pd.Grouper(level='date', freq='W-FRI')]).sum()\n",
    "    print(ttdf.head())\n",
    "    return ttdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def com_not_at_date(tdf, datestr):\n",
    "    \"\"\"\n",
    "    returns list of companies(symbols) that do not \n",
    "    have data at given date.\n",
    "    \"\"\"\n",
    "    rcom = []\n",
    "    for sym in set(tdf.index.get_level_values('symbol')):\n",
    "        if not ((sym, pd.Timestamp(datestr)) in tdf.index):\n",
    "            rcom.append(sym)\n",
    "    print(f\"companies not at date {datestr}: {rcom}\")\n",
    "    return rcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(tdf, rcom):\n",
    "    \"\"\"\n",
    "    Takes dataframe and list of companies and to drops rows\n",
    "    from the df using index level 0 (symbol) (does it inplace)\n",
    "    \"\"\"\n",
    "    for com in rcom:\n",
    "        if com in tdf.index.get_level_values(\"symbol\"):\n",
    "            tdf.drop(com, level=\"symbol\", inplace=True)\n",
    "            print(f\"{com} removed\")\n",
    "        else:\n",
    "            print(f\"{com} not found\")\n",
    "    print(tdf.head())\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store it in the database\n",
    "def df_to_db(tdf, dbname):\n",
    "        conn = sqlite3.connect(dbname)\n",
    "        tdf.to_sql(name='eow', con=conn, if_exists='replace', index=True, index_label=['symbol', 'date'])\n",
    "        conn.close()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date symbol      open      high       low     close  adjclose  \\\n",
      "0 2019-09-20    MMM  167.4300  169.1700  166.4800  166.7600  166.7600   \n",
      "1 2019-09-19    MMM  167.3900  168.8100  166.9100  167.0700  167.0700   \n",
      "2 2019-09-18    MMM  167.6100  168.0500  165.2500  167.4400  167.4400   \n",
      "3 2019-09-17    MMM  167.7600  168.5700  166.5000  168.0700  168.0700   \n",
      "4 2019-09-16    MMM  171.2100  171.2100  167.9100  169.6700  169.6700   \n",
      "\n",
      "    volume dividend splitcoeff  \n",
      "0  2817420   0.0000     1.0000  \n",
      "1  1623000   0.0000     1.0000  \n",
      "2  2096700   0.0000     1.0000  \n",
      "3  2716400   0.0000     1.0000  \n",
      "4  2459300   0.0000     1.0000  \n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "df = get_df_from_db(\"stocks.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index              128\n",
      "date          18201600\n",
      "symbol        18201600\n",
      "open          18201600\n",
      "high          18201600\n",
      "low           18201600\n",
      "close         18201600\n",
      "adjclose      18201600\n",
      "volume        18201600\n",
      "dividend      18201600\n",
      "splitcoeff    18201600\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Optimize columns\n",
    "df = optimize_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date symbol    open    high     low   close  adjclose   volume\n",
      "0 2019-09-20    MMM  167.43  169.17  166.48  166.76    166.76  2817420\n",
      "1 2019-09-19    MMM  167.39  168.81  166.91  167.07    167.07  1623000\n",
      "2 2019-09-18    MMM  167.61  168.05  165.25  167.44    167.44  2096700\n",
      "3 2019-09-17    MMM  167.76  168.57  166.50  168.07    168.07  2716400\n",
      "4 2019-09-16    MMM  171.21  171.21  167.91  169.67    169.67  2459300\n"
     ]
    }
   ],
   "source": [
    "# Remove split and dividends\n",
    "df = remove_unwanted_columns(df, ['dividend', 'splitcoeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     open    high     low   close  adjclose    volume company\n",
      "symbol date                                                                  \n",
      "A      1999-11-18  45.500  49.750  40.000  44.000   27.2534  62546300       A\n",
      "       1999-11-19  42.938  43.000  39.813  40.375   25.0081  15234100       A\n",
      "       1999-11-22  41.313  44.000  40.063  44.000   27.2534   6577800       A\n",
      "       1999-11-23  42.500  43.625  40.000  40.000   24.7758   5975600       A\n",
      "       1999-11-24  40.125  41.938  40.000  41.063   25.4339   4843200       A\n"
     ]
    }
   ],
   "source": [
    "# Configure indices\n",
    "df = index_operations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [(A, 2011-01-07 00:00:00), (A, 2011-01-14 00:00:00), (A, 2011-01-21 00:00:00), (A, 2011-01-28 00:00:00), (A, 2011-02-04 00:00:00)]\n"
     ]
    }
   ],
   "source": [
    "# Create new df\n",
    "ndf = create_newdf(df, '2011-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  company     open     high    low  close  adjclose    volume\n",
      "symbol date                                                                  \n",
      "A      2011-01-07       A  41.5600  42.1391  41.00  41.62   27.3601  23040100\n",
      "       2011-01-14       A  41.4100  43.4100  41.30  43.26   28.4382  17917600\n",
      "       2011-01-21       A  43.3700  44.4500  41.46  42.11   27.6822  21525200\n",
      "       2011-01-28       A  42.1834  43.5200  40.88  40.98   26.9394  22294000\n",
      "       2011-02-04       A  41.2100  43.1300  40.23  42.99   28.2607  27637800\n"
     ]
    }
   ],
   "source": [
    "# Resample columns\n",
    "ndf = resample_columns(df, ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222069, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "companies not at date 2011-01-07: ['NLSN', 'COTY', 'HII', 'NWS', 'FOXA', 'ABBV', 'IQV', 'FTV', 'TWTR', 'XYL', 'FB', 'ALLE', 'TRIP', 'INFO', 'QRVO', 'HLT', 'KHC', 'PYPL', 'CPRI', 'AMCR', 'NWSA', 'FANG', 'LW', 'HPE', 'NCLH', 'APTV', 'KEYS', 'HCA', 'WRK', 'MPC', 'SYF', 'UA', 'PSX', 'FOX', 'ZTS', 'DOW', 'CFG', 'FBHS', 'CTVA', 'ANET', 'KMI']\n"
     ]
    }
   ],
   "source": [
    "# Get company  list not at given date\n",
    "rcom = com_not_at_date(ndf, '2011-01-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLSN removed\n",
      "COTY removed\n",
      "HII removed\n",
      "NWS removed\n",
      "FOXA removed\n",
      "ABBV removed\n",
      "IQV removed\n",
      "FTV removed\n",
      "TWTR removed\n",
      "XYL removed\n",
      "FB removed\n",
      "ALLE removed\n",
      "TRIP removed\n",
      "INFO removed\n",
      "QRVO removed\n",
      "HLT removed\n",
      "KHC removed\n",
      "PYPL removed\n",
      "CPRI removed\n",
      "AMCR removed\n",
      "NWSA removed\n",
      "FANG removed\n",
      "LW removed\n",
      "HPE removed\n",
      "NCLH removed\n",
      "APTV removed\n",
      "KEYS removed\n",
      "HCA removed\n",
      "WRK removed\n",
      "MPC removed\n",
      "SYF removed\n",
      "UA removed\n",
      "PSX removed\n",
      "FOX removed\n",
      "ZTS removed\n",
      "DOW removed\n",
      "CFG removed\n",
      "FBHS removed\n",
      "CTVA removed\n",
      "ANET removed\n",
      "KMI removed\n",
      "                  company     open     high    low  close  adjclose    volume\n",
      "symbol date                                                                  \n",
      "A      2011-01-07       A  41.5600  42.1391  41.00  41.62   27.3601  23040100\n",
      "       2011-01-14       A  41.4100  43.4100  41.30  43.26   28.4382  17917600\n",
      "       2011-01-21       A  43.3700  44.4500  41.46  42.11   27.6822  21525200\n",
      "       2011-01-28       A  42.1834  43.5200  40.88  40.98   26.9394  22294000\n",
      "       2011-02-04       A  41.2100  43.1300  40.23  42.99   28.2607  27637800\n"
     ]
    }
   ],
   "source": [
    "# Drop unwanted companies\n",
    "ndf = drop_rows(ndf, rcom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store it to sqlite db\n",
    "df_to_db(ndf, \"stocks-eow.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data-cleaning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
